{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset, trainx and testx refers to training and test image\n",
    "trainy and testy refers to the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to flatten the image within 784 pixels (28 *  28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(60000, 784)   #leads to loss of 2D structure\n",
    "test_x = test_x.reshape(10000, 784)\n",
    "\n",
    "train_y = keras.utils.to_categorical(train_y, 10)\n",
    "test = keras.utils.to_categorical(test_y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is ready to be trained\n",
    "Let's define our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()    #sequential list of layers\n",
    "model.add(Dense(units = 128, activation = 'relu', input_shape = (784, )))\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dense(units = 128, activation = 'relu'))\n",
    "model.add(Dense(units = 10, activation = 'softmax'))   #Dense means it's connected to each neuron before it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNTIS?\n",
    "this is the number of neurons in each layer\n",
    "MORE UNITS === MORE COMPUTATIONALLY EXPENSIVE\n",
    "*******************************NEVER SET TO MORE THAN 512******************************************************\n",
    "\n",
    "SHAPE?\n",
    "note the reshape we did earlier, we just have to specify in the first layer, and then Keras infers the rest.\n",
    "\n",
    "ACTIVATION?\n",
    "activation funt is a math function that transforms the input to the required output within a certain range\n",
    "ReLU (Rectified Linear Unit) is the most used activation function\n",
    "ReLU is non-linear or piecewise linear function that outputs the input directly, IFF POSITIVE, otherwise ZERO\n",
    "commonly used in neural networks, like Convolutional Neural Networks and Multilayer perceptrons\n",
    "\n",
    "FINAL LAYER?\n",
    "10 UNITS? for our output, we want a 1 dimensional array vector of probabilities of each image within any of the 10 classes of digits (0 - 9)\n",
    "\n",
    "SOFTMAX ACTIVATION?\n",
    "    - takes a set of scores for N classes, 10 in this case, and transform them into probabilities so that the total sum is exactly 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's specify a few more components to train on our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = SGD(0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ask Keras to compile our model with the right components.\n",
    "Let's go over them one by one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OPTIMIZER**\n",
    "When we train neural networks, the update both parameters step by step defined by the learning rate\n",
    "\n",
    "**The most common optimozer is called Stochastic Gradient Descent (SGD)**\n",
    "\n",
    "**Stochastic** means randomly\n",
    "\n",
    "**Gradient** means slope\n",
    "\n",
    "**Descent** means to go lower\n",
    "\n",
    "SGD updates it's parameters using a technique called backpropagation\n",
    "\n",
    "(0.001 is our learning rate or alpha value)\n",
    "\n",
    "**Categorical Cross Entropy**\n",
    "SGD uses a loss function to comput derivatives\n",
    "Metrics is just reporting our accuracy back to us\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Num CPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.3167 - accuracy: 0.9161\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2624 - accuracy: 0.9269\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2403 - accuracy: 0.9315\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2252 - accuracy: 0.9355\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2132 - accuracy: 0.9384\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.2029 - accuracy: 0.9406\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1940 - accuracy: 0.9434\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1864 - accuracy: 0.9452\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1797 - accuracy: 0.9469\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 1s 2ms/step - loss: 0.1739 - accuracy: 0.9483\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"z:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"z:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"z:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"z:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1667, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"z:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"z:\\python\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"z:\\python\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"z:\\python\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"z:\\python\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"z:\\python\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (100, 1) and (100, 10) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model\u001b[39m.\u001b[39mfit(train_x, train_y, batch_size \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m, epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m, verbose \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mevaluate(x \u001b[39m=\u001b[39;49m test_x, y \u001b[39m=\u001b[39;49m test_y, batch_size \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m \u001b[39mprint\u001b[39m(accuracy)\n",
      "File \u001b[1;32mz:\\python\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file5tkwhpmw.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"z:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1727, in test_function  *\n        return step_function(self, iterator)\n    File \"z:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1713, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"z:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1701, in run_step  **\n        outputs = model.test_step(data)\n    File \"z:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1667, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"z:\\python\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n        return self.compiled_loss(\n    File \"z:\\python\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"z:\\python\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"z:\\python\\lib\\site-packages\\keras\\losses.py\", line 272, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"z:\\python\\lib\\site-packages\\keras\\losses.py\", line 1990, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"z:\\python\\lib\\site-packages\\keras\\backend.py\", line 5529, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (100, 1) and (100, 10) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, batch_size = 100, epochs = 10, verbose = 1)\n",
    "accuracy = model.evaluate(x = test_x, y = test_y, batch_size = 100)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab8fbcbd1ec96f2b934f7be264b12bfa1a69e566f2b7e2b05c394a66cfd7a4e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
